<!DOCTYPE html>

<html>

<head lang="fr">
    <meta charset="UTF-8" />
    <title>La justice prédictive pour les nuls</title>
    <link rel="stylesheet" href="Style.css" />
    <link rel="icon" href="img/logo.ico"/>
    <link href="https://fonts.googleapis.com/css?family=Muli" rel="stylesheet">
</head>

  <body>
        <header>
      <ul id="menu-deroulant">
        <li><a href="index.html">La justice prédictive pour les nuls</a>
        <li><a href="#">Les Parties</a>
          <ul>
            <li><a href="introduction.html">Introduction</a></li>
            <li><a href="methode.html">La méthode</a></li>
            <li><a href="algorithmes.html">La Fiabilité des algorithme</a></li>
            <li><a href="marchandisation.html">Marchandisation de la justice</a></li>
            <li><a href="dangers.html">Les Dangers de la justice prédictive</a></li>
            <li><a href="citoyens.html">Les citoyens et la justice predictive</a></li>
            <li><a href="conciliation.html">La conciliation Homme-Robot</a></li>
            <li><a href="conclusion.html">Conclusion</a></li>
            <li><a href="annexes.html">Annexes</a></li>
          </ul>
    </header>


      <div class="box_img">
        <h1>Les dangers de la justice prédicive sur l'idéal de justice</h1>
        <img src="">
      </div>

      <div class="box_contenu">
      <h3>Les dangers de la justice prédicive sur l'idéal de justice</h3>
      <h4 id="ancre1">Le manque de fiabilité des algorithmes pose la question de la fiabilité des jugements </h4>

      <p class="text_basic">Aujourd’hui deux services prétendant faire de la justice prédictive s’affrontent pour conquérir les avocats. Prédictice et cause Analytics. Le problème c’est qu’aujourd’hui beaucoup de contentieux se règlent en dehors des juridictions ce qui tend à poser la question de l’utilité actuelle de tels services. Pour autant certains cabinets jugent l’arrivée de ces services comme un premier pas vers la justice numérique. En revanche, le doute subsiste sur la capacité des machines à fournir des informations claires. En effet beaucoup de justiciables et de juristes ne connaissent pas ou n’ont que très peu confiance en ces algorithmes qui produisent des résultats. </p>

      <p class="text_basic">Ces problèmes de fiabilité et de transparence se ressentent et pose la question d’une compatibilité avec l’idéal de justice dans la mesure où celle-ci doit demeurer la plus transparente possible. Dans le même ordre d’idée la justice prédictive pourrait-elle mettre fin au secret professionnel des avocats ? Cette question taraude les professionnels qui voit l’arrivée de l’intelligence de la justice dans leur domaine comme une véritable menace pour leur sécurité et l’exercice de leurs fonction qui doit selon les serments actuels prononcés par les avocats respecter le principe de soumission au secret professionnel. La question des droits des avocats.</p>

      <p class="text_basic">La justice prédictive induit l’arrivée de services proposées par des entreprises privées comme prédictice par exemple. Cette situation implique la création d’un véritable marché de la justice où les entreprises proposeraient des services payant à des cabinets d’avocats ou à des juges pour traiter les problèmes judiciaires des populations. Cette avancée dans le temps s’oppose à l’idéal de la justice. En effet la justice est un service public gratuit accessible à tous. L’apparition de ce marché amènerait à la création d’inégalités entre les justiciables, les avocats et les magistrats ce qui semble évidemment contraire au principe de justice. L’usage d’appareil d’intelligence artificielle aurait en effet pour conséquence l’augmentation des honoraires des avocats. Or tous les justiciables ne peuvent suivre cette inflation et créerait des inégalités dans les capacités de défenses. Face à ces argumentations, les partisans de la justice prédictive avancent que les aides à la décision juridique par les machines permettront aux avocats d’informer les potentiels clients sur les possibilités de gagner un procès et l’opportunité du lancement de procédure. Ainsi les justiciables pourrait économiser du temps et de l’argent si les avantages sont quasiment nuls.
Pour autant il faut veiller à préserver la notion de service public de la justice pour garantir l’accessibilité à tous et l’Egalité car nous vivons dans un Etat de droits où les droits de tous les citoyens doivent être scrupuleusement respectés
</p>

      <p class="text_basic">La responsabilité pose problème dans le cadre d’une intelligence artificielle. En droit la responsabilité civile se divise en deux branches : délictuelle et contractuelle c’est à dire celle d’un avocat envers son client. C’est celle qui nous intéresse. Aux termes de l'article 1147 du Code civil, « le débiteur est condamné, s'il y a lieu, au paiement de dommages et intérêts, soit en raison de l'inexécution de l'obligation, soit à raison du retard dans l'exécution ». Elle intervient quand le créancier n'a pu obtenir exécution de la chose, selon les termes du contrat, de la part de son débiteur. Si un avocat conseille mal son client, il est responsable. </p>

      <p class="text_basic">Donc on voit que malgré la merveille de progrès qu’est la justice prédictive, plane le spectre de la responsabilité professionnelle. Comment l'avocat expliquera-t-il à son client que la « machine » l'a orienté vers un « mauvais procès » plutôt que vers une médiation réussie, ou lui a conseillé une stratégie qui s'est finalement révélée perdante ? Lorsque l’avocat fait une erreur, le résultat est le même mais au moins, on sait qui l’a commise et on sait à qui s’en prendre. Ici, on ne sait pas. En plus, même si on dit souvent que l’erreur est humaine et qu’une machine fait en général moins d’erreur, c’est difficilement acceptable lorsqu’on confie un dossier qui peut jouer sa vie. L’aspect humanisé du droit peut rassurer les clients en quelque sorte. Une machine, on a l’impression qu’elle peut s’éteindre ou “bugger” pour utiliser le terme familier à tout moment, qu’elle est moins fiable. Donc même si les algorithmes prédictifs pourrait permettre d’éviter une longue et coûteuse procédure dans un litige dont la part d’aléa paraît réduite, l’accès au juge et les principes du procès équitable doivent rester la règle. Le recours au juge ne doit pas être dissuadé sur la base de données qui ne seraient pas entièrement fiables et qui pourraient même être biaisées.</p>

      <p class="text_basic">La fiabilité du jugement remis en cause car lors d’un jugement aujourd’hui on vise à l’égalité mais aussi surtout à l’équité. La différence est la suivante : L'égalité repose sur la volonté d'offrir la même chose à tous les gens pour qu'ils puissent s'épanouir et vivre des vies saines. L’équité elle n’offre pas la même chose à tout le monde car elle essaye de pallier aux inégalités présentent à la base.  « On a confiance en un juge parce qu’il est indépendant et humain », souligne Maître Winston Maxwell, avocat associé chez Hogan Lovells, spécialiste en régulation numérique. « En Angleterre, au XVIIe siècle, il existait deux formes de justice, l’application de la loi pure et dure, et le tribunal en équité sous la responsabilité du roi, qui permettait de pallier la rigidité de la première », poursuit-il. Certains disent que la justice prédictive n’est pas acceptable, car chaque cas est unique et qu’elle ne prend pas assez en compte certaines subtilités et donc n’est pas équitable. </p>

      <p class="text_basic">Et en même temps si on décidait de donner au robot la capacité de devenir équitable et de reproduire le schéma humain, la machine peut devenir très inégalitaire en fonction de ce qu’elle a retenu et c’est dangereux. Elle peut tomber pas dans le piège des préjugés comme cela peut arriver à l’homme. « L’intelligence artificielle s’appuie, pour beaucoup, sur une analyse du passé. Même si un algorithme n’est pas biaisé, en principe, il réintègre les biais humains », reprend Me Winston Maxwell. Il donne l’exemple de Tay, l’intelligence artificielle lancée par Microsoft en mars 2016 qui s’est mise à tenir des propos racistes, antisémites et misogynes en quelques heures. Censée apprendre au fil de ses échanges avec les internautes, elle s’est mise à ressembler à ceux qu’elle a côtoyés en ligne alors qu’un être juge n’est pas censé être une éponge à ce point. </p>

      <h4 id="ancre2">La justice prédictive menace l’indépendance de la justice et l’adaptabilité du droit  </h4>

      <p class="text_basic">Le risque des logiciels prédictifs est que le juge, sous l’effet de la surveillance résultant d’un traitement massif des décisions de justice, perde sa liberté d’appréciation et son indépendance et préfère se ranger, par « sécurité », à l’opinion dominante ou majoritaire de ses pairs. On constate une perte d’indépendance de l’autorité judiciaire pourtant inscrite dans l’article 64 de la Constitution : </p>

      <p class="text_italic">“Le Président de la République est garant de l’indépendance de l’autorité judiciaire.Il est assisté par le Conseil Supérieur de la Magistrature. Une loi organique porte statut des magistrats. Les magistrats du siège sont inamovibles.” Ici, le risque de la justice prédictive va totalement à l’encontre de la notion de droit telle qu’elle est entendue dans la Constitution."</p>

      <p class="text_basic">Le propre de la justice est que chaque affaire doit être examinée pour ce qu’elle est, avec sa part d’originalité et d’irréductible complexité qui ne saurait être systématisée par un logiciel, aussi puissant soit-il. Même dans un contentieux de masse ou très répétitif, l’expérience et la capacité personnelles et professionnelles des juges sont essentielles. L’aspect psychologique et de prise en compte des circonstances des infractions risque de disparaitre et cela serait très dangereux pour les futurs jugements de déshumanisé complètement la justice en préférant mettre en œuvre des robots pour la décision judiciaire.</p>

      <p class="text_basic">Le droit risque de se retrouver dans une phase stationnaire, c’est-à-dire qu’aucune évolution ne pourra être apporté dans la conception de la matière juridique puisque tous les résultats seront déjà consignés dans un algorithme. 
Il en résulterait une rigidification du droit. En effet, le droit dans sa pratique n’a pas comme seule source le texte. La coutume, le contexte, des tous petits points de détails de l’enquête, ou même le regard innocent du condamné peuvent eux aussi jouer un rôle normatif et coercitif. “Dans une décision de justice subsiste un aléa irréductible. D’un cas à l’autre, le même juge ne va pas prendre la même décision. « La justice prédictive est un concept non seulement vide de sens car il n’y a rien à prédire, mais dangereux car la machine ne va pas prédire mais prescrire », disait Jacques Lévy Vehel ancien chercheur à l’Institut national de recherche en informatique et en automatique (Inria), qui a cofondé Case Law Analytics avec le magistrat Jérôme Dupré.
</p>

      <p class="text_basic">Il insistait surtout sur les débats lors d’une audience sont importants pour rendre une décision juste « A un moment, il faut que les gens puissent parler, et on ne peut pas faire l’économie d’un débat contradictoire », insiste Jacques Lévy Vehel. Pour lui il y a un risque avec le fait de régler trop de questions en amont. Certains choses méritent d’être débattues et pas d’être renvoyées à la jurisprudence.</p>

      <p class="text_basic">Les revirements de jurisprudence de la Cour de cassation, explique le professeur Joël Monéger, resteront très difficiles à anticiper pour un algorithme
On peut imaginer que les résultats produits par les algorithmes risquent d’être répétés et amplifiés et toute décision « atypique », même justifiée, risquera de paraître inacceptable, si elle n’est pas spécialement et très fortement motivée. S’il est aisé d’ordonner à une machine de respecter un texte de loi, il est pratiquement impossible de lui demander d’effectuer un revirement de jurisprudence dans un cas précis, car le choix est parfois politique et nécessite une conscience (or la machine n’a pas de conscience). Le renversement de jurisprudence serait rendu impossible. En effet, la machine pour prédire un résultat, utilise des probabilités, ce qui implique qu’elle réalise des moyennes. Or si un juge décide de changer de jurisprudence et que la machine se base sur les données inscrites dans son logiciel et en fait une moyenne, le résultat sera contraire à celui du juge. L’algorithme se fait ici le chantre du conservatisme du droit, puisqu’il empêche tout revirement de la jurisprudence. Sans porter de jugement de valeur, on peut constater que son utilisation conférera au droit un uniformisme certain. On se rend compte que l’adaptablité de cette technologie pose aujourd’hui question, notamment dans les pays dans lesquels le droit coutumier joue un rôle important. 
</p>

      
    
       
      </div>


      <div class="box_plan_chapitre">
        <ul>
          <li class="chapitre_liste"><a href="#ancre1">I.   Fiabilité des jugements</a></li>
          <li class="chapitre_liste"><a href="#ancre2">II.  Les menaces</a></li>
        </ul>
      </div>

	</body>
</html>